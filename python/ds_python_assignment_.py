# -*- coding: utf-8 -*-
"""DS_Python_Assignment .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Mzaxd_KOBWw9jPqBuuy-mvWTsuAeG_v0

Question 1: -

Write a program that takes a string as input, and counts the frequency of each word in the string, there might be repeated characters in the string. Your task is to find the highest frequency and returns the length of the highest-frequency word.
Note - You have to write at least 2 additional test cases in which your program will run successfully and provide an explanation for the same.
Example input - string = “write write write all the number from from from 1 to 100”
Example output - 5
Explanation - From the given string we can note that the most frequent words are “write” and “from” and
the maximum value of both the values is “write” and its corresponding length is 5
"""

def find_highest_frequency_word_length(string):
    # Split the string into words
    words = string.split()

    # Count the frequency of each word
    word_frequency = {}
    for word in words:
        word_frequency[word] = word_frequency.get(word, 0) + 1

    # Find the maximum frequency
    max_frequency = max(word_frequency.values())

    # Find the length of the word with the maximum frequency
    max_frequency_word_length = max(len(word) for word, frequency in word_frequency.items() if frequency == max_frequency)

    return max_frequency_word_length

# Test case 1
string = "write write write all the number from from from 1 to 100"
print(find_highest_frequency_word_length(string))
# Output: 5

# Test case 2
string = "apple apple banana banana banana cherry cherry"
print(find_highest_frequency_word_length(string))
# Output: 6
# Explanation: The most frequent word is "cherry" with a frequency of 3, and its length is 6.

# Test case 3
string = "hello hello world world world world"
print(find_highest_frequency_word_length(string))
# Output: 5
# Explanation: The most frequent word is "world" with a frequency of 4, and its length is 5.

"""Question 2: -

Consider a string to be valid if all characters of the string appear the same number of times. It is also valid if
he can remove just one character at the index in the string, and the remaining characters will occur the same
number of times. Given a string, determine if it is valid. If so, return YES , otherwise return NO .

Note - You have to write at least 2 additional test cases in which your program will run successfully and provide
an explanation for the same.
Example input 1 - s = “abc”. This is a valid string because frequencies are { “a”: 1, “b”: 1, “c”: 1 }
Example output 1- YES
Example input 2 - s “abcc”. This string is not valid as we can remove only 1 occurrence of “c”. That leaves
character frequencies of { “a”: 1, “b”: 1 , “c”: 2 }
Example output 2 - NO
"""

def is_valid_string(s):
    # Count the frequency of each character
    char_count = {}
    for char in s:
        char_count[char] = char_count.get(char, 0) + 1
    
    # Count the frequency of frequencies
    freq_count = {}
    for count in char_count.values():
        freq_count[count] = freq_count.get(count, 0) + 1

    # If there is only one frequency, it's a valid string
    if len(freq_count) == 1:
        return "YES"
    # If there are more than two frequencies, it's not a valid string
    elif len(freq_count) > 2:
        return "NO"
    else:
        # Check if we can remove one character to make frequencies equal
        freq_list = list(freq_count.items())
        if (freq_list[0][0] == 1 and freq_list[0][1] == 1) or (freq_list[1][0] == 1 and freq_list[1][1] == 1):
            return "YES"
        elif (freq_list[0][0] - freq_list[1][0]) == 1 and (freq_list[0][1] == 1 or freq_list[1][1] == 1):
            return "YES"
        else:
            return "NO"

# Example 1
s = "abc"
print(is_valid_string(s))
# Output: YES

# Example 2
s = "abcc"
print(is_valid_string(s))
# Output: NO

"""Question 3: -
Write a program, which would download the data from the provided link, and then read the data and convert
that into properly structured data and return it in Excel format.
Note - Write comments wherever necessary explaining the code written.

Link - https://raw.githubusercontent.com/Biuni/PokemonGO-Pokedex/master/pokedex.json

Data Attributes - id: Identification Number - int num: Number of the
● Pokémon in the official Pokédex - int name: Pokémon name -

● string img: URL to an image of this Pokémon - string type:

● Pokémon type -string height: Pokémon height - float

● weight: Pokémon weight - float candy: type of candy used to evolve Pokémon or given

● when transferred - string candy_count: the amount of candies required to evolve
- int

● egg: Number of kilometers to travel to hatch the egg - float spawn_chance:

● Percentage of spawn chance (NEW) - float avg_spawns: Number of this
pokemon on 10.000 spawns (NEW) - int

● spawn_time: Spawns most active at the time on this field. Spawn times are the same for all
time zones and are expressed in local time. (NEW) - “minutes: seconds” multipliers:
Multiplier of Combat Power (CP) for calculating the CP after evolution See below - list of int
weakness: Types of

● Pokémon this Pokémon is weak to - list of strings next_evolution: Number and Name of
successive evolutions of Pokémon - list of dict prev_evolution: Number and Name of previous
evolutions of Pokémon - - list of dict
"""

import requests
import pandas as pd

def download_data(url):
    response = requests.get(url)  # Send a GET request to the URL
    data = response.json()  # Get the JSON data from the response
    return data

def convert_to_excel(data):
    # Extract the required attributes from the data
    columns = ['id', 'num', 'name', 'img', 'type', 'height', 'weight', 'candy', 'candy_count', 'egg', 'spawn_chance', 'avg_spawns', 'spawn_time', 'multipliers', 'weaknesses', 'next_evolution', 'prev_evolution']
    rows = []
    for pokemon in data['pokemon']:
        row = []
        for column in columns:
            value = pokemon.get(column, '')
            row.append(value)
        rows.append(row)
    
    # Create a pandas DataFrame with the extracted data
    df = pd.DataFrame(rows, columns=columns)
    
    # Save the DataFrame to an Excel file
    excel_file = 'pokemon_data.xlsx'
    df.to_excel(excel_file, index=False)
    
    return excel_file

# Download the data from the provided link
url = 'https://raw.githubusercontent.com/Biuni/PokemonGO-Pokedex/master/pokedex.json'
data = download_data(url)

# Convert the data to Excel format
excel_file = convert_to_excel(data)
print(f"Data has been successfully converted and saved to {excel_file}")

import pandas as pd
k=pd.read_excel("pokemon_data.xlsx")
k

import pandas as pd

# Assuming you have a DataFrame named 'df' containing the data

# Export the DataFrame to an Excel file
output_file = 'pokemon_data.xlsx'
k.to_excel(output_file, index=False)
print(f"Data has been successfully exported to {output_file}.")

output_file = '/content/pokemon_data.xlsx'
k.to_excel(output_file, index=False)

"""Question 4 -

Write a program to download the data from the link given below and then read the data and convert the into
the proper structure and return it as a CSV file.
Link - https://data.nasa.gov/resource/y77d-th95.json

Note - Write code comments wherever needed for code understanding.

Sample Data -

Excepted Output Data Attributes

● Name of Earth Meteorite - string id - ID of Earth

● Meteorite - int nametype - string recclass - string

● mass - Mass of Earth Meteorite - float year - Year at which Earth

● Meteorite was hit - datetime format reclat - float recclong - float

● point coordinates - list of int
"""

import requests
import csv

def download_data(url):
    response = requests.get(url)  # Send a GET request to the URL
    data = response.json()  # Get the JSON data from the response
    return data

def convert_to_csv(data):
    # Define the CSV file path
    csv_file = 'meteorite_data.csv'
    
    # Extract the required attributes from the data
    attributes = ['name', 'id', 'nametype', 'recclass', 'mass (g)', 'year', 'reclat', 'reclong']
    
    # Open the CSV file in write mode
    with open(csv_file, 'w', newline='') as file:
        writer = csv.DictWriter(file, fieldnames=attributes)
        
        # Write the CSV header
        writer.writeheader()
        
        # Write each row of data as a CSV row
        for meteorite in data:
            row = {attr: meteorite.get(attr, '') for attr in attributes}
            writer.writerow(row)
    
    return csv_file

# Download the data from the provided link
url = 'https://data.nasa.gov/resource/y77d-th95.json'
data = download_data(url)

# Convert the data to CSV format
csv_file = convert_to_csv(data)
print(f"Data has been successfully converted and saved to {csv_file}")

import pandas as pd
d=pd.read_csv("meteorite_data.csv")
d

"""Question 5 -
Write a program to download the data from the given API link and then extract the following data with
proper formatting

Link - http://api.tvmaze.com/singlesearch/shows?q=westworld&embed=episodes
Note - Write proper code comments wherever needed for the code understanding

Sample Data -

Excepted Output Data Attributes -
● id - int url - string

● name - string season

● - int number - int

● type - string airdate -

● date format airtime -

● 12-hour time format

● runtime - float

● average rating - float

● summary - string

● without html tags

● medium image link - string

● Original image link - string
"""

import requests

def download_data(url):
    response = requests.get(url)  # Send a GET request to the URL
    data = response.json()  # Get the JSON data from the response
    return data

def extract_show_data(data):
    show_id = data.get('id', '')
    show_url = data.get('url', '')
    show_name = data.get('name', '')
    show_type = data.get('type', '')
    show_summary = data.get('summary', '').replace('<p>', '').replace('</p>', '')
    
    image_data = data.get('image', {})
    image_medium = image_data.get('medium', '')
    image_original = image_data.get('original', '')
    
    show_data = {
        'id': show_id,
        'url': show_url,
        'name': show_name,
        'type': show_type,
        'summary': show_summary,
        'medium_image': image_medium,
        'original_image': image_original
    }
    
    return show_data

def extract_episode_data(data):
    episodes = data.get('_embedded', {}).get('episodes', [])
    
    episode_data = []
    for episode in episodes:
        episode_id = episode.get('id', '')
        episode_season = episode.get('season', '')
        episode_number = episode.get('number', '')
        episode_airdate = episode.get('airdate', '')
        episode_airtime = episode.get('airtime', '')
        episode_runtime = episode.get('runtime', '')
        episode_rating = episode.get('rating', {}).get('average', '')
        episode_summary = episode.get('summary', '').replace('<p>', '').replace('</p>', '')
        
        episode_entry = {
            'id': episode_id,
            'season': episode_season,
            'number': episode_number,
            'airdate': episode_airdate,
            'airtime': episode_airtime,
            'runtime': episode_runtime,
            'average_rating': episode_rating,
            'summary': episode_summary
        }
        
        episode_data.append(episode_entry)
    
    return episode_data

# Download the data from the provided API link
url = 'http://api.tvmaze.com/singlesearch/shows?q=westworld&embed=episodes'
data = download_data(url)

# Extract the show data and episode data with proper formatting
show_data = extract_show_data(data)
episode_data = extract_episode_data(data)

# Print the extracted show data
print("Show Data:")
print("---------")
for key, value in show_data.items():
    print(f"{key}: {value}")
print()

# Print the extracted episode data
print("Episode Data:")
print("------------")
for episode in episode_data:
    print("Episode:")
    for key, value in episode.items():
        print(f"{key}: {value}")
    print()

"""Question 6 -
Using the data from Question 3, write code to analyze the data and answer the following questions Note 1.
Draw plots to demonstrate the analysis for the following questions for better visualizations.
2. Write code comments wherever required for code understanding

Insights to be drawn -
● Get all Pokemons whose spawn rate is less than 5%

● Get all Pokemons that have less than 4 weaknesses

● Get all Pokemons that have no multipliers at all

● Get all Pokemons that do not have more than 2 evolutions

● Get all Pokemons whose spawn time is less than 300 seconds.

Note - spawn time format is "05:32”, so assume “minute: second” format and perform the analysis.

● Get all Pokemon who have more than two types of capabilities
"""

import pandas as pd
import matplotlib.pyplot as plt

import pandas as pd
import matplotlib.pyplot as plt

# Question 1: Get all Pokemons whose spawn rate is less than 5%
spawn_rate_threshold = 5
spawn_rate_less_than_threshold = data[data['spawn_chance'] < spawn_rate_threshold]
print(f"Number of Pokemons with spawn rate less than {spawn_rate_threshold}%: {len(spawn_rate_less_than_threshold)}")
print(spawn_rate_less_than_threshold)

# Plot the spawn rate distribution
plt.hist(data['spawn_chance'], bins=20)
plt.xlabel('Spawn Rate')
plt.ylabel('Count')
plt.title('Distribution of Spawn Rates')
plt.show()

# Question 2: Get all Pokemons that have less than 4 weaknesses
max_weaknesses = 4
less_than_max_weaknesses = data[data['weaknesses'].apply(lambda x: len(x) < max_weaknesses)]
print(f"Number of Pokemons with less than {max_weaknesses} weaknesses: {len(less_than_max_weaknesses)}")
print(less_than_max_weaknesses)

# Question 3: Get all Pokemons that have no multipliers at all
no_multipliers = data[data['multipliers'].isna()]
print("Number of Pokemons with no multipliers:", len(no_multipliers))
print(no_multipliers)

# Question 4: Get all Pokemons that do not have more than 2 evolutions
import numpy as np

max_evolutions = 2
less_than_max_evolutions = data[data['next_evolution'].apply(lambda x: len(x) if isinstance(x, list) else np.nan) <= max_evolutions]
print(f"Number of Pokemons with 2 or fewer evolutions: {len(less_than_max_evolutions)}")
print(less_than_max_evolutions)

# Question 5: Get all Pokemons whose spawn time is less than 300 seconds
spawn_time_threshold = '05:00'
data['spawn_time'] = pd.to_datetime(data['spawn_time'], format='%M:%S')
less_than_spawn_time_threshold = data[data['spawn_time'] < pd.to_datetime(spawn_time_threshold, format='%M:%S')]
print(f"Number of Pokemons with spawn time less than {spawn_time_threshold}: {len(less_than_spawn_time_threshold)}")
print(less_than_spawn_time_threshold)

# Question 6: Get all Pokemon who have more than two types of capabilities
min_types = 2
more_than_min_types = data[data['type'].apply(lambda x: len(x.split(','))) > min_types]
print(f"Number of Pokemons with more than {min_types} types: {len(more_than_min_types)}")
print(more_than_min_types)

"""Question 7 -

Using the data from Question 4, write code to analyze the data and answer the following questions Note -
1. Draw plots to demonstrate the analysis for the following questions for better visualizations
2. Write code comments wherever required for code understanding

Insights to be drawn -

● Get all the Earth meteorites that fell before the year 2000

● Get all the earth meteorites co-ordinates who fell before the year 1970

● Assuming that the mass of the earth meteorites was in kg, get all those whose mass was more
than 10000kg
"""

import pandas as pd
import requests
import datetime

# Download data from the API link
url = "https://data.nasa.gov/resource/y77d-th95.json"
response = requests.get(url)
data = pd.DataFrame(response.json())

data.head()

data.info()

# Convert the year column to datetime format with 'coerce' option
data['year'] = pd.to_datetime(data['year'], errors='coerce')

# Filter the Earth meteorites that fell before the year 2000
before_year_2000 = data[data['year'] < pd.Timestamp('2000-01-01')]
print(f"Number of Earth meteorites that fell before the year 2000: {len(before_year_2000)}")
print(before_year_2000)

# Plot the mass distribution of Earth meteorites
plt.hist(data['mass'].astype(float), bins=20)
plt.xlabel('Mass (kg)')
plt.ylabel('Count')
plt.title('Distribution of Earth Meteorite Mass')
plt.show()

# Filter the Earth meteorites' coordinates that fell before the year 1970
before_year_1970 = data[data['year'] < pd.Timestamp('1970-01-01')]
print(f"Number of Earth meteorites' coordinates that fell before the year 1970: {len(before_year_1970)}")
print(before_year_1970)

# Filter the Earth meteorites with a mass greater than 10000 kg
greater_than_10000kg = data[data['mass'].astype(float) > 10000]
print(f"Number of Earth meteorites with a mass greater than 10000 kg: {len(greater_than_10000kg)}")
print(greater_than_10000kg)

# Plot the mass distribution of Earth meteorites with a mass greater than 10000 kg
plt.hist(greater_than_10000kg['mass'].astype(float), bins=20)
plt.xlabel('Mass (kg)')
plt.ylabel('Count')
plt.title('Distribution of Earth Meteorite Mass > 10000 kg')
plt.show()

"""Question 8 -

Using the data from Question 5, write code the analyze the data and answer the following questions Note -
1. Draw plots to demonstrate the analysis for the following questions and better visualizations
2. Write code comments wherever required for code understanding

Insights to be drawn -

● Get all the overall ratings for each season and using plots compare the ratings for all the
seasons, like season 1 ratings, season 2, and so on.

● Get all the episode names, whose average rating is more than 8 for every season

● Get all the episode names that aired before May 2019

● Get the episode name from each season with the highest and lowest rating

● Get the summary for the most popular ( ratings ) episode in every season
"""

import pandas as pd
import requests
import matplotlib.pyplot as plt
import seaborn as sns

# Download data from the API link
url = "http://api.tvmaze.com/singlesearch/shows?q=westworld&embed=episodes"
response = requests.get(url)
data = pd.DataFrame(response.json()["_embedded"]["episodes"])

# Convert airdate column to datetime format
data['airdate'] = pd.to_datetime(data['airdate'])

# Convert rating column to numeric type
data['rating'] = pd.to_numeric(data['rating'], errors='coerce')

# Drop rows with missing values in rating column
data = data.dropna(subset=['rating'])

# Get all the overall ratings for each season
season_ratings = data.groupby('season')['rating'].mean()

# Get all the episode names with average rating > 8 for every season
high_rated_episodes = data.groupby(['season', 'name'])['rating'].mean().reset_index()
high_rated_episodes = high_rated_episodes[high_rated_episodes['rating'] > 8]

# Get all the episode names that aired before May 2019
before_may_2019 = data[data['airdate'] < pd.Timestamp('2019-05-01')]['name']

# Get the episode name with the highest and lowest rating from each season
highest_rated_episodes = data.groupby('season')['rating'].idxmax().apply(lambda x: data.loc[x, 'name'])
lowest_rated_episodes = data.groupby('season')['rating'].idxmin().apply(lambda x: data.loc[x, 'name'])

# Get the summary for the most popular episode in every season (highest rating)
popular_episodes_summary = data.groupby('season')['rating'].idxmax().apply(lambda x: data.loc[x, 'summary'])

# Print the results
print("Overall Ratings for Each Season:")
print(season_ratings)
print("\nEpisode Names with Average Rating > 8 for Every Season:")
print(high_rated_episodes)
print("\nEpisode Names Aired Before May 2019:")
print(before_may_2019)
print("\nEpisode with Highest Rating from Each Season:")
print(highest_rated_episodes)
print("\nEpisode with Lowest Rating from Each Season:")
print(lowest_rated_episodes)
print("\nSummary for Most Popular Episode in Every Season:")
print(popular_episodes_summary)

"""Question 9 -

Write a program to read the data from the following link, perform data analysis and answer the following
questions
Note -
1. Write code comments wherever required for code understanding
Link - https://data.wa.gov/api/views/f6w7-q2d2/rows.csv?accessType=DOWNLOAD

Insights to be drawn -

● Get all the cars and their types that do not qualify for clean alternative fuel vehicle

● Get all TESLA cars with the model year, and model type made in Bothell City.

● Get all the cars that have an electric range of more than 100, and were made after
2015

● Draw plots to show the distribution between city and electric vehicle type
"""

import pandas as pd
import matplotlib.pyplot as plt

# Read the data from the CSV file
data_url = "https://data.wa.gov/api/views/f6w7-q2d2/rows.csv?accessType=DOWNLOAD"
df = pd.read_csv(data_url)

df.head()

# Rename the columns for easier access
#df.rename(columns={'Electric Vehicle Type': 'ELECTRIC_VEHICLE_TYPE',
                   'Electric Range': 'ELECTRIC_RANGE',
                   'Clean Alternative Fuel Vehicle': 'CLEAN_ALTERNATIVE_FUEL_VEHICLE'},
          inplace=True)

# Get the column names
column_names = df.columns

# Find the column names containing the required information
electric_vehicle_type_col = next((col for col in column_names if 'Electric Vehicle Type' in col), None)
electric_range_col = next((col for col in column_names if 'Electric Range' in col), None)
clean_alt_fuel_vehicle_col = next((col for col in column_names if 'Clean Alternative Fuel Vehicle' in col), None)
make_col = next((col for col in column_names if 'Make' in col), None)
model_col = next((col for col in column_names if 'Model' in col), None)
year_col = next((col for col in column_names if 'Year' in col), None)
city_col = next((col for col in column_names if 'City' in col), None)

# Get all the cars and their types that do not qualify for clean alternative fuel vehicle
non_clean_cars = df[df[clean_alt_fuel_vehicle_col] == 'No']
non_clean_cars_info = non_clean_cars[[make_col, model_col]]
print("Cars that do not qualify for clean alternative fuel vehicle:")
print(non_clean_cars_info)

# Get all TESLA cars with the model year and model type made in Bothell City
tesla_cars_bothell = df[(df[make_col] == 'TESLA') & (df[city_col] == 'BOTHELL')]
tesla_cars_info = tesla_cars_bothell[[year_col, model_col]]
print("TESLA cars made in Bothell City:")
print(tesla_cars_info)

# Get all the cars that have an electric range of more than 100 and were made after 2015
electric_cars_range_100 = df[(df['Electric Range'] > 100) & (df['Year'] > 2015)]
electric_cars_range_100_info = electric_cars_range_100[['Make', 'Model', 'Year', 'Electric Range']]
print("Cars with electric range > 100 and made after 2015:")
print(electric_cars_range_100_info)

# Plot the distribution between city and electric vehicle type
city_ev_type_counts = df.groupby(['City', 'Electric Vehicle Type']).size().unstack(fill_value=0)
city_ev_type_counts.plot(kind='bar', stacked=True)
plt.title('Distribution of City and Electric Vehicle Type')
plt.xlabel('City')
plt.ylabel('Count')
plt.show()

"""Question 10 -

Write a program to count the number of verbs, nouns, pronouns, and adjectives in a given particular phrase or
paragraph, and return their respective count as a dictionary.
Note -
1. Write code comments wherever required for code
2. You have to write at least 2 additional test cases in which your program will run successfully and provide
an explanation for the same.
"""

nltk.download('averaged_perceptron_tagger')

import nltk
from nltk import pos_tag
from nltk.tokenize import word_tokenize
from tensorflow.keras.preprocessing.text import Tokenizer 
from tensorflow.keras.preprocessing.sequence import pad_sequences

def count_pos_tags(text):
    # Tokenize the text into words
    words = word_tokenize(text)

    # Perform part-of-speech tagging
    tagged_words = pos_tag(words)

    # Initialize count variables
    verb_count = 0
    noun_count = 0
    pronoun_count = 0
    adjective_count = 0

    # Count the occurrences of each part of speech
    for word, tag in tagged_words:
        if tag.startswith('VB'):
            verb_count += 1
        elif tag.startswith('NN'):
            noun_count += 1
        elif tag.startswith('PRP'):
            pronoun_count += 1
        elif tag.startswith('JJ'):
            adjective_count += 1

    # Create a dictionary to store the counts
    pos_counts = {
        'Verbs': verb_count,
        'Nouns': noun_count,
        'Pronouns': pronoun_count,
        'Adjectives': adjective_count
    }

    return pos_counts

# Test the function with example phrases
text1 = "I like to eat pizza"
text2 = "The cat chased the mouse"
text3 = "She is a smart and friendly person"

pos_counts1 = count_pos_tags(text1)
print("Counts for text 1:", pos_counts1)

pos_counts2 = count_pos_tags(text2)
print("Counts for text 2:", pos_counts2)

pos_counts3 = count_pos_tags(text3)
print("Counts for text 3:", pos_counts3)